import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df_customers=pd.read_csv('customers.csv')
df_customers.head()
df_loans=pd.read_csv('loans.csv')
df_loans.head()
df_bureau=pd.read_csv('bureau_data.csv')
df_bureau.head()
import pandas as pd
import numpy as np

# Set seed for reproducibility
np.random.seed(42)

n = 50000

# Customer IDs formatted C00001...
cust_ids = np.array([f"C{str(i).zfill(5)}" for i in range(1, n + 1)])

# Monthly income / inflow
inflow = np.random.normal(50000, 15000, n).clip(5000, None).astype(int)

# Monthly spend (bounded below by 0 and less than inflow)
spend = (inflow * np.random.uniform(0.2, 0.95, n)).astype(int)

# Past loan performance score (0=bad,1=average,2=good,3=excellent)
loan_perf = np.random.choice([0,1,2,3], size=n, p=[0.15,0.35,0.35,0.15])

# Count of previous loans
past_loans = np.random.poisson(2, n)

# Number of defaults historically
defaults = np.random.binomial(p=0.1, n=past_loans)

# Credit score dependent on loan performance + income randomness
base_score = 300 + (loan_perf * 150) + np.random.normal(0, 40, n)
credit_score = np.clip(base_score, 300, 900).astype(int)

# Account balance trend: inflow minus spend with noise
avg_balance = (inflow - spend) * np.random.uniform(0.5, 1.5, n)
avg_balance = avg_balance.clip(0, None).astype(int)

df_transaction = pd.DataFrame({
    "cust_id": cust_ids,
    "monthly_inflow": inflow,
    "monthly_spend": spend,
    "avg_monthly_balance": avg_balance,
    "past_loan_count": past_loans,
    "past_defaults": defaults,
    "loan_performance_rating": loan_perf,
    "credit_score": credit_score
})








df_transaction.head()
df_transaction.shape
df=df_customers.merge(df_loans,on='cust_id')
df=df.merge(df_bureau,on='cust_id')

df=df.merge(df_transaction,on='cust_id')
df.shape
df.head()
df.info()
df['default']=df['default'].astype('int')
df.info()
# data cleaning
df.isnull().mean()*100
df['residence_type'].value_counts()
mode_residance=df["residence_type"].mode()[0]
mode_residance
df["residence_type"].fillna(mode_residance,inplace=True)
# checking for duplicate value
df.duplicated().sum()
# there is no duplicated rows present in the data
df.select_dtypes(include=["int64","float64"]).columns
df.select_dtypes(include="object").columns
columns_continuous = ['age', 'income', 'number_of_dependants', 'years_at_current_address',
       'zipcode', 'sanction_amount', 'loan_amount', 'processing_fee', 'gst',
       'net_disbursement', 'loan_tenure_months', 'principal_outstanding',
       'bank_balance_at_application', 'number_of_open_accounts',
       'number_of_closed_accounts', 'total_loan_months', 'delinquent_months',
       'total_dpd', 'enquiry_count', 'credit_utilization_ratio',
       'monthly_inflow', 'monthly_spend', 'avg_monthly_balance',
       'loan_performance_rating', 'credit_score']

columns_categorical = ['gender', 'marital_status', 'employment_status',
       'residence_type', 'city', 'state', 'loan_id', 'loan_purpose',
       'loan_type', 'disbursal_date', 'installment_start_dt']
rows = (len(columns_continuous) + 2) //3
fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))
axes = axes.flatten() 

for i, col in enumerate(columns_continuous):
    axes[i].boxplot(df[col])
    axes[i].set_title(col)

for j in range(i + 1, len(axes)):
    axes[j].set_visible(False)

plt.tight_layout()
plt.show()
df['processing_fee'].describe()
df["loan_amount"].describe()
df[df['processing_fee']>0.03*df["loan_amount"]]
# there are some rows where processing fee are greater than loan_amount so i will remove this
df1=df[df["processing_fee"]<0.03*df['loan_amount']].copy()
for col in columns_categorical:
    print(col, "-->", df1[col].unique())
df1['loan_purpose'].value_counts()
df1["loan_purpose"]=df1["loan_purpose"].replace("Personaal","Personal")
df1["loan_purpose"].unique()
# EDA
import math

n = len(columns_continuous)
rows = math.ceil(n / 4)  # 4 per row, change if you want

fig, axes = plt.subplots(rows, 4, figsize=(16, rows*4))
axes = axes.flatten()

for i, col in enumerate(columns_continuous):
    sns.kdeplot(df1[col][df1['default']==0], fill=True, ax=axes[i], label='default=0')
    sns.kdeplot(df1[col][df1['default']==1], fill=True, ax=axes[i], label='default=1')
    axes[i].legend()

plt.tight_layout()



# Feature Engineering part
df1["loan_to_income"]=round(df["loan_amount"]/df["income"],2)
plt.figure(figsize=(8, 4))
sns.kdeplot(df1[df1["default"]==0]["loan_to_income"],fill=True,label="default0")
sns.kdeplot(df1[df1["default"]==1]["loan_to_income"],fill=True,label="default1")
plt.legend()
plt.show()
df1['delinquency_ratio'] = (df1['delinquent_months']*100 / df1['total_loan_months']).round(1)

plt.figure(figsize=(8, 4))
sns.kdeplot(df1['delinquency_ratio'][df1['default'] == 0], fill=True, label='default=0')
sns.kdeplot(df1['delinquency_ratio'][df1['default'] == 1], fill=True, label='default=1')
plt.title(f"Delinquency Ratio KDE Plot with Hue by default")
plt.legend()
plt.show()
df1['avg_dpd_per_delinquency'] = np.where(
    df1['delinquent_months'] != 0,
    (df1['total_dpd'] / df1['delinquent_months']).round(1),
    0
)
plt.figure(figsize=(8, 4))
sns.kdeplot(df1['avg_dpd_per_delinquency'][df1['default'] == 0], fill=True, label='default=0')
sns.kdeplot(df1['avg_dpd_per_delinquency'][df1['default'] == 1], fill=True, label='default=1')
plt.title(f"Avg DPD Per Delinquency Ratio KDE Plot with Hue by default")
plt.legend()
plt.show()
df1['monthly_spent_r']=round(df['monthly_spend']/df['monthly_inflow'])
plt.figure(figsize=(8, 4))
sns.kdeplot(df1[df1["default"]==0]["monthly_spent_r"],fill=True,label="default0")
sns.kdeplot(df1[df1["default"]==1]["monthly_spent_r"],fill=True,label="default1")
plt.legend()
plt.show()
# Feature Selection
df2 = df1.drop(['cust_id', 'loan_id'],axis="columns")
df3 = df2.drop(['disbursal_date', 'installment_start_dt', 'loan_amount', 'income', 
                              'total_loan_months', 'delinquent_months', 'total_dpd'], axis="columns")
df3.columns
df3.head()
numeric_columns=df3.select_dtypes(include=["int64","float64"]).columns


numeric_columns = [
    col for col in df3.select_dtypes(include=["int64","float64"]).columns
    if col != 'default'
]

df_Xtrain4 = df3.drop('default', axis='columns')

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

df_Xtrain4[numeric_columns] = scaler.fit_transform(df_Xtrain4[numeric_columns])

df_Xtrain4[numeric_columns].head()
from statsmodels.stats.outliers_influence import variance_inflation_factor
def calculate_vif(data):
    vif_data = pd.DataFrame()
    vif_data["feature"] = data.columns
    vif_data["VIF"] =[variance_inflation_factor(data.values,i) for i in range(data.shape[1])]
    return vif_data
calculate_vif(df_Xtrain4[numeric_columns])
df_X_train_41=df_Xtrain4.drop(columns=['age','credit_score','monthly_inflow','monthly_spend','loan_performance_rating','avg_monthly_balance','processing_fee', 'gst',"principal_outstanding","sanction_amount"],axis=1)
numeric_columns=df_X_train_41.select_dtypes(["int64","float64"]).columns
calculate_vif(df_X_train_41[numeric_columns])
# weight of Evidence and information value
def calculate_iv(df,feature,target):
    grouped=df.groupby(feature)[target].agg(["count","sum"])
    grouped.rename(columns={"count":"total","sum":"good"},inplace=True)
    grouped["bad"]=grouped["total"]-grouped["good"]
    grouped["good_pct"]=grouped["good"]/grouped["good"].sum()
    grouped["bad_pct"]=grouped["bad"]/grouped["bad"].sum()
    grouped["woe"]=np.log( grouped["good_pct"]/grouped["bad_pct"])
    grouped["iv"]= grouped["woe"]*(grouped["good_pct"]-grouped["bad_pct"])
    total_iv = grouped['iv'].sum()
    return total_iv
import numpy as np
iv_values = {}

for feature in df_X_train_41.columns:
    
    # Check categorical
    if df_X_train_41[feature].dtype == "object":
        temp_df = pd.concat([df_X_train_41[[feature]], df3['default']], axis=1)
        iv = calculate_iv(temp_df, feature, "default")
    
    else:
        # Bin numerical vars
        X_binned = pd.cut(df_X_train_41[feature], bins=10, labels=False).to_frame(feature)
        temp_df = pd.concat([X_binned, df3['default']], axis=1)
        iv = calculate_iv(temp_df, feature, "default")
    
    iv_values[feature] = iv

iv_values

iv_df=pd.DataFrame(iv_values.items(),columns=["feature","iv"])
iv_df
selected_features=[]
selected_features = [feature for feature, iv in iv_values.items() if iv > 0.02]
selected_features
df_train5 = df_X_train_41[selected_features]

df_train5.head()
# Applying one hot encoding
df_train_encoded = pd.get_dummies(df_train5, drop_first=True)
df_train_encoded.head(3)
df_train_encoded.columns
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(df_train_encoded,df3["default"], test_size=0.2, random_state=42)
X_train.shape
y_train.shape
# Training model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

lr = LogisticRegression()
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
Rfc=RandomForestClassifier()
Rfc.fit(X_train,y_train)
y_pred=Rfc.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
from xgboost import XGBClassifier

model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
from lightgbm import LGBMClassifier

model = LGBMClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# Confusion Matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Precision / Recall / F1 Score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# AUC Score (uses predicted probability)
y_prob = model.predict_proba(X_test)[:,1]
print("\nROC AUC Score:", roc_auc_score(y_test, y_prob))


# RandomizedSearchCv
from sklearn.model_selection import RandomizedSearchCV
log_reg=LogisticRegression(max_iter=1000)
param_grid={'C': np.logspace(-4, 4, 20), "solver":["newton-cg", "sag","lbfgs"]}
random_search=RandomizedSearchCV(log_reg,param_distributions=param_grid,n_iter=50, scoring='f1', n_jobs=-1,cv=3,verbose=2,random_state=42)
random_search.fit(X_train, y_train)
print(f"Best Parameters: {random_search.best_params_}")
print(f"Best Score: {random_search.best_score_}")
best_model = random_search.best_estimator_
y_pred=best_model.predict(X_test)
print(classification_report(y_test,y_pred))
from scipy.stats import uniform, randint
from sklearn.model_selection import RandomizedSearchCV

# Define parameter distribution for RandomizedSearchCV
param_dist = {
    'n_estimators': [100, 150, 200, 250, 300],
    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],
    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'scale_pos_weight': [1, 2, 3, 5, 7, 10],
    'reg_alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0],
    'reg_lambda': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0] 
}

xgb = XGBClassifier()

random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_dist, n_iter=100,
                                   scoring='f1', cv=3, verbose=1, n_jobs=-1, random_state=42)

random_search.fit(X_train, y_train)

# Print the best parameters and best score
print(f"Best Parameters: {random_search.best_params_}")
print(f"Best Score: {random_search.best_score_}")
best_model = random_search.best_estimator_
y_pred = best_model.predict(X_test)
print("Classification Report:")
print(classification_report(y_test, y_pred))
from lightgbm import LGBMClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score
from scipy.stats import randint, uniform

# Base model
lgbm = LGBMClassifier(objective='binary', boosting_type='gbdt', n_jobs=-1)

# Search space
param_dist = {
    'num_leaves': randint(20, 200),
    'max_depth': randint(3, 12),
    'learning_rate': uniform(0.005, 0.3),
    'n_estimators': randint(100, 1000),
    'min_child_samples': randint(10, 200),
    'subsample': uniform(0.5, 0.5),
    'colsample_bytree': uniform(0.5, 0.5),
    'reg_alpha': uniform(0, 1),
    'reg_lambda': uniform(0, 1)
}

# Randomized Search (fast)
lgb_random = RandomizedSearchCV(
    estimator=lgbm,
    param_distributions=param_dist,
    n_iter=25,        # reduce if slow, increase if want more search
    scoring='roc_auc',
    cv=5,
    verbose=2,
    random_state=42,
    n_jobs=-1
)

# Fit
lgb_random.fit(X_train, y_train)

print("Best Parameters:", lgb_random.best_params_)

# Predict
best_model = lgb_random.best_estimator_
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:,1]

# Evaluate
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nROC AUC:", roc_auc_score(y_test, y_prob))

# underSampling
from imblearn.under_sampling import RandomUnderSampler
rus=RandomUnderSampler(random_state=42)
X_train_res,y_train_res=rus.fit_resample(X_train,y_train)
y_train.value_counts()
y_train_res.value_counts()
model = LogisticRegression(solver='sag', C=29.763514416313132)
model.fit(X_train_res,y_train_res)

y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print(report)
model = XGBClassifier(**random_search.best_params_)
model.fit(X_train_res, y_train_res)

y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print(report)
# oversampling
from imblearn.combine import SMOTETomek

smt = SMOTETomek(random_state=42)
X_train_smt, y_train_smt = smt.fit_resample(X_train, y_train)
y_train_smt.value_counts()
model = LogisticRegression(solver='sag', C=29.763514416313132)
model.fit(X_train_smt, y_train_smt)

y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print(report)
model = XGBClassifier(**random_search.best_params_)
model.fit(X_train_smt, y_train_smt)

y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print(report)
# Optuna
import optuna
from sklearn.metrics import make_scorer, f1_score
from sklearn.model_selection import cross_val_score
def objective(trial):
    param={'C':trial.suggest_float('C', 1e-4, 1e4, log=True),
    'solver':trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga', 'newton-cg']),
    'tol':trial.suggest_float('tol', 1e-6, 1e-1, log=True),
    'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced'])}
    model = LogisticRegression(**param, max_iter=10000)
    f1_scorer = make_scorer(f1_score, average='macro')
    scores = cross_val_score(model, X_train_smt, y_train_smt, cv=3, scoring=f1_scorer, n_jobs=-1)
    return np.mean(scores)
study_logistic = optuna.create_study(direction='maximize')
study_logistic.optimize(objective, n_trials=50)
study_logistic .best_params
best_model_logistic = LogisticRegression(**study_logistic.best_params)
best_model_logistic.fit(X_train_smt, y_train_smt)

# Evaluate on the test set
y_pred = best_model_logistic.predict(X_test)

report = classification_report(y_test, y_pred)
print(report)
best_model_logistic
# ROC-AUC CURVE
from sklearn.metrics import roc_curve

probabilities =best_model_logistic.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, probabilities)

fpr[:5], tpr[:5], thresholds[:5]
from sklearn.metrics import auc

area = auc(fpr, tpr)
area.round(2)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area ={area.round(2)})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend()
plt.show()
df_imp=pd.DataFrame()
df_imp["feature"]=X_train.columns
df_imp["coefficients"]=best_model_logistic.coef_[0]
df_imp=df_imp.sort_values(by="coefficients",ascending=False)
sns.barplot(x=df_imp["coefficients"],y=df_imp["feature"])
probabilities = best_model_logistic.predict_proba(X_test)[:,1]

df_eval = pd.DataFrame({
    'Default Truth': y_test,
    'Default Probability': probabilities
})
df_eval.head(3)
df_eval['Decile'] = pd.qcut(df_eval['Default Probability'], 10, labels=False, duplicates='drop')
df_eval.head(3)
df_eval[df_eval.Decile==8]['Default Probability'].describe()
df_decile = df_eval.groupby('Decile').apply(lambda x: pd.Series({
    'Minimum Probability': x['Default Probability'].min(),
    'Maximum Probability': x['Default Probability'].max(),
    'Events': x['Default Truth'].sum(),
    'Non-events': x['Default Truth'].count() - x['Default Truth'].sum(),    
}))
df_decile.reset_index(inplace=True)
df_decile
df_decile['Event Rate'] = df_decile['Events']*100 / (df_decile['Events']+df_decile['Non-events'])
df_decile['Non-event Rate'] = df_decile['Non-events']*100 / (df_decile['Events']+df_decile['Non-events'])
df_decile
df_decile = df_decile.sort_values(by='Decile', ascending=False).reset_index(drop=True)
df_decile
df_decile['Cum Events'] =  df_decile['Events'].cumsum()
df_decile['Cum Non-events'] =  df_decile['Non-events'].cumsum()
df_decile
df_decile['Cum Event Rate'] = df_decile['Cum Events'] * 100 / df_decile['Events'].sum()
df_decile['Cum Non-event Rate'] = df_decile['Cum Non-events']*100 / df_decile['Non-events'].sum()
df_decile
df_decile['KS'] = abs(df_decile['Cum Event Rate'] - df_decile['Cum Non-event Rate'])
df_decile

gini_coefficient = 2 * area - 1

print("AUC:", area)
print("Gini Coefficient:", gini_coefficient)
